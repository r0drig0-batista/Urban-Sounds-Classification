{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
      "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
      "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
      "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
      "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
      "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
      "\n",
      "              class  \n",
      "0          dog_bark  \n",
      "1  children_playing  \n",
      "2  children_playing  \n",
      "3  children_playing  \n",
      "4  children_playing  \n"
     ]
    }
   ],
   "source": [
    "metadata_path = r\"C:\\Users\\admin\\Desktop\\AC II\\UrbanSound8K\\metadata\\UrbanSound8K.csv\"\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "print(metadata.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processamento concluído e dados salvos!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# Parâmetros\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 4  # em segundos\n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE * DURATION\n",
    "\n",
    "# Caminho para o dataset\n",
    "input_path = r\"C:\\Users\\admin\\Desktop\\AC II\\UrbanSound8K\\audio\"\n",
    "metadata_path = r\"C:\\Users\\admin\\Desktop\\AC II\\UrbanSound8K\\metadata\\UrbanSound8K.csv\"\n",
    "output_base_path = r\"C:\\Users\\admin\\Desktop\\AC II\\ProcessedAudio\"\n",
    "\n",
    "# Carregar o arquivo de metadados\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Função para padronizar o áudio (padding ou repeat)\n",
    "def preprocess_audio(file_path, method=\"padding\", sample_rate=SAMPLE_RATE, duration=DURATION):\n",
    "    try:\n",
    "        # Carregar o áudio\n",
    "        signal, sr = librosa.load(file_path, sr=sample_rate)\n",
    "        target_length = sample_rate * duration\n",
    "\n",
    "        # Ajustar o tamanho do sinal\n",
    "        if len(signal) < target_length:\n",
    "            if method == \"padding\":\n",
    "                # Adicionar zeros\n",
    "                signal = np.pad(signal, (0, target_length - len(signal)), 'constant')\n",
    "            elif method == \"repeat\":\n",
    "                # Repetir o som\n",
    "                repeat_count = target_length // len(signal) + 1\n",
    "                signal = np.tile(signal, repeat_count)[:target_length]\n",
    "        else:\n",
    "            # Truncar o sinal longo\n",
    "            signal = signal[:target_length]\n",
    "\n",
    "        return signal\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Criar as pastas de saída (padding e repeat)\n",
    "os.makedirs(os.path.join(output_base_path, \"padding\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(output_base_path, \"repeat\"), exist_ok=True)\n",
    "\n",
    "for folder in range(1, 11):  # UrbanSound8K possui folders de 1 a 10\n",
    "    os.makedirs(os.path.join(output_base_path, \"padding\", f\"fold{folder}\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output_base_path, \"repeat\", f\"fold{folder}\"), exist_ok=True)\n",
    "\n",
    "# Adicionar o caminho completo dos arquivos ao dataframe\n",
    "metadata['file_path'] = metadata.apply(\n",
    "    lambda row: os.path.join(input_path, f\"fold{row['fold']}\", row['slice_file_name']), axis=1\n",
    ")\n",
    "\n",
    "# Processar e salvar os áudios\n",
    "for index, row in metadata.iterrows():\n",
    "    file_path = row['file_path']\n",
    "    fold = row['fold']\n",
    "    file_name = row['slice_file_name']\n",
    "    \n",
    "    # Processar com padding\n",
    "    signal_padding = preprocess_audio(file_path, method=\"padding\")\n",
    "    if signal_padding is not None:\n",
    "        output_folder_padding = os.path.join(output_base_path, \"padding\", f\"fold{fold}\")\n",
    "        np.save(os.path.join(output_folder_padding, file_name.replace('.wav', '.npy')), signal_padding)\n",
    "\n",
    "    # Processar com repeat\n",
    "    signal_repeat = preprocess_audio(file_path, method=\"repeat\")\n",
    "    if signal_repeat is not None:\n",
    "        output_folder_repeat = os.path.join(output_base_path, \"repeat\", f\"fold{fold}\")\n",
    "        np.save(os.path.join(output_folder_repeat, file_name.replace('.wav', '.npy')), signal_repeat)\n",
    "\n",
    "print(\"Processamento concluído e dados salvos!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extração de MFCCs concluída!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "def extract_mel_spectrogram(signal, sample_rate=22050, n_mels=128):\n",
    "    \"\"\"\n",
    "    Extrai o espectrograma de Mel do sinal de áudio.\n",
    "    \"\"\"\n",
    "    S = librosa.feature.melspectrogram(y=signal, sr=sample_rate, n_mels=n_mels)\n",
    "    return librosa.power_to_db(S).T  # Converte para dB e transpõe\n",
    "\n",
    "# Ainda nao extrai o espetograma, mas é util para o CNN 2D. Para isso basta substituir la em baixo a funçao e tambem os arquivos\n",
    "\n",
    "def extract_mfcc(signal, sample_rate=22050, n_mfcc=13):\n",
    "    \"\"\"\n",
    "    Extrai os MFCCs do sinal de áudio.\n",
    "    \"\"\"\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=n_mfcc)\n",
    "    return mfccs.T  # Transpor para ter (tempo x coeficientes)\n",
    "\n",
    "# Caminho para os sinais processados (ex.: padding)\n",
    "processed_data_path = r\"C:\\Users\\admin\\Desktop\\AC II\\ProcessedAudio\\repeat\"\n",
    "\n",
    "# Caminho para salvar os MFCCs\n",
    "output_mfcc_path = r\"C:\\Users\\admin\\Desktop\\AC II\\MFCCs\\repeat\"\n",
    "os.makedirs(output_mfcc_path, exist_ok=True)\n",
    "\n",
    "# Loop pelos folds\n",
    "for fold in range(1, 11):\n",
    "    input_folder = os.path.join(processed_data_path, f\"fold{fold}\")\n",
    "    output_folder = os.path.join(output_mfcc_path, f\"fold{fold}\")\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(input_folder):\n",
    "        if file.endswith(\".npy\"):\n",
    "            # Carregar o sinal\n",
    "            signal = np.load(os.path.join(input_folder, file))\n",
    "            \n",
    "            # Extrair MFCCs\n",
    "            mfcc = extract_mfcc(signal)\n",
    "            \n",
    "            # Salvar os MFCCs como numpy array\n",
    "            np.save(os.path.join(output_folder, file), mfcc)\n",
    "\n",
    "print(\"Extração de MFCCs concluída!\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aqui começa a parte do MLP, onde os valores são achatados para ficarem em uma dimensão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de folds: 10\n",
      "Tamanho do Fold 1: (873, 2249), (873,)\n"
     ]
    }
   ],
   "source": [
    "def load_mfccs_by_fold(folder_path):\n",
    "    \"\"\"\n",
    "    Carrega os MFCCs organizados por fold.\n",
    "    \"\"\"\n",
    "    X_folds = []  # Lista de arrays X para cada fold\n",
    "    y_folds = []  # Lista de arrays y para cada fold\n",
    "\n",
    "    for fold in range(1, 11):  # UrbanSound8K tem 10 folds\n",
    "        fold_path = os.path.join(folder_path, f\"fold{fold}\")\n",
    "        X_fold = []\n",
    "        y_fold = []\n",
    "\n",
    "        for file in os.listdir(fold_path):\n",
    "            if file.endswith(\".npy\"):\n",
    "                # Carregar o MFCC\n",
    "                mfcc = np.load(os.path.join(fold_path, file))\n",
    "\n",
    "                # Achatar o MFCC\n",
    "                flattened = mfcc.flatten()\n",
    "                X_fold.append(flattened)\n",
    "\n",
    "                # Associar o rótulo\n",
    "                label = int(file.split(\"-\")[1])  # Exemplo: \"7061-6-0-0.npy\" -> classe 6\n",
    "                y_fold.append(label)\n",
    "\n",
    "        X_folds.append(np.array(X_fold))\n",
    "        y_folds.append(np.array(y_fold))\n",
    "\n",
    "    return X_folds, y_folds\n",
    "\n",
    "# Caminho para os MFCCs processados\n",
    "mfcc_folder_path = r\"C:\\Users\\admin\\Desktop\\AC II\\MFCCs\\padding\"\n",
    "X_folds, y_folds = load_mfccs_by_fold(mfcc_folder_path)\n",
    "\n",
    "print(f\"Número de folds: {len(X_folds)}\")\n",
    "print(f\"Tamanho do Fold 1: {X_folds[0].shape}, {y_folds[0].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 512)               1152000   \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1317514 (5.03 MB)\n",
      "Trainable params: 1317514 (5.03 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Transformar os rótulos para one-hot encoding\n",
    "y = to_categorical(y, num_classes=10)\n",
    "\n",
    "# Criar o modelo\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X.shape[1],)),  # Primeira camada oculta\n",
    "    Dropout(0.3),  # Dropout para evitar overfitting\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(10, activation='softmax')  # Camada de saída (10 classes)\n",
    "])\n",
    "\n",
    "# Compilar o modelo\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteração 1:\n",
      "Treino: (6287, 2249), Validação: (1572, 2249), Teste: (873, 2249)\n",
      "Iteração 2:\n",
      "Treino: (6275, 2249), Validação: (1569, 2249), Teste: (888, 2249)\n",
      "Iteração 3:\n",
      "Treino: (6245, 2249), Validação: (1562, 2249), Teste: (925, 2249)\n",
      "Iteração 4:\n",
      "Treino: (6193, 2249), Validação: (1549, 2249), Teste: (990, 2249)\n",
      "Iteração 5:\n",
      "Treino: (6236, 2249), Validação: (1560, 2249), Teste: (936, 2249)\n",
      "Iteração 6:\n",
      "Treino: (6327, 2249), Validação: (1582, 2249), Teste: (823, 2249)\n",
      "Iteração 7:\n",
      "Treino: (6315, 2249), Validação: (1579, 2249), Teste: (838, 2249)\n",
      "Iteração 8:\n",
      "Treino: (6340, 2249), Validação: (1586, 2249), Teste: (806, 2249)\n",
      "Iteração 9:\n",
      "Treino: (6332, 2249), Validação: (1584, 2249), Teste: (816, 2249)\n",
      "Iteração 10:\n",
      "Treino: (6316, 2249), Validação: (1579, 2249), Teste: (837, 2249)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for test_fold_idx in range(10):  # 10 folds no UrbanSound8K\n",
    "    # Teste: O fold atual\n",
    "    X_test = X_folds[test_fold_idx]\n",
    "    y_test = y_folds[test_fold_idx]\n",
    "\n",
    "    # Treino + Validação: Os demais folds\n",
    "    X_train_val = np.concatenate([X_folds[i] for i in range(10) if i != test_fold_idx], axis=0)\n",
    "    y_train_val = np.concatenate([y_folds[i] for i in range(10) if i != test_fold_idx], axis=0)\n",
    "\n",
    "    # Normalizar os dados\n",
    "    scaler = StandardScaler()\n",
    "    X_train_val = scaler.fit_transform(X_train_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Divisão treino/validação\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"Iteração {test_fold_idx + 1}:\")\n",
    "    print(f\"Treino: {X_train.shape}, Validação: {X_val.shape}, Teste: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "197/197 [==============================] - 3s 10ms/step - loss: 1.8396 - accuracy: 0.4002 - val_loss: 1.2456 - val_accuracy: 0.5941\n",
      "Epoch 2/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 1.4108 - accuracy: 0.5233 - val_loss: 1.0761 - val_accuracy: 0.6330\n",
      "Epoch 3/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 1.2685 - accuracy: 0.5680 - val_loss: 0.9598 - val_accuracy: 0.6781\n",
      "Epoch 4/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 1.1486 - accuracy: 0.6087 - val_loss: 0.8858 - val_accuracy: 0.7010\n",
      "Epoch 5/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 1.0190 - accuracy: 0.6480 - val_loss: 0.7990 - val_accuracy: 0.7494\n",
      "Epoch 6/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.9701 - accuracy: 0.6730 - val_loss: 0.8123 - val_accuracy: 0.7436\n",
      "Epoch 7/50\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.9028 - accuracy: 0.6868 - val_loss: 0.7345 - val_accuracy: 0.7354\n",
      "Epoch 8/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.8757 - accuracy: 0.7003 - val_loss: 0.6967 - val_accuracy: 0.7627\n",
      "Epoch 9/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.8422 - accuracy: 0.7113 - val_loss: 0.7092 - val_accuracy: 0.7704\n",
      "Epoch 10/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.7500 - accuracy: 0.7431 - val_loss: 0.6496 - val_accuracy: 0.7863\n",
      "Epoch 11/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.7344 - accuracy: 0.7490 - val_loss: 0.6594 - val_accuracy: 0.7805\n",
      "Epoch 12/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.7114 - accuracy: 0.7560 - val_loss: 0.6191 - val_accuracy: 0.7971\n",
      "Epoch 13/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.6647 - accuracy: 0.7733 - val_loss: 0.6300 - val_accuracy: 0.8009\n",
      "Epoch 14/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.6602 - accuracy: 0.7821 - val_loss: 0.6333 - val_accuracy: 0.7977\n",
      "Epoch 15/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.6060 - accuracy: 0.7896 - val_loss: 0.5753 - val_accuracy: 0.8053\n",
      "Epoch 16/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.6281 - accuracy: 0.7838 - val_loss: 0.6609 - val_accuracy: 0.7901\n",
      "Epoch 17/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.5703 - accuracy: 0.8045 - val_loss: 0.5978 - val_accuracy: 0.8003\n",
      "Epoch 18/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.5491 - accuracy: 0.8136 - val_loss: 0.5863 - val_accuracy: 0.8098\n",
      "Epoch 19/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.5669 - accuracy: 0.8029 - val_loss: 0.5610 - val_accuracy: 0.8142\n",
      "Epoch 20/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.5435 - accuracy: 0.8164 - val_loss: 0.6759 - val_accuracy: 0.7990\n",
      "Epoch 21/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.5425 - accuracy: 0.8222 - val_loss: 0.6018 - val_accuracy: 0.8149\n",
      "Epoch 22/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.5027 - accuracy: 0.8311 - val_loss: 0.6172 - val_accuracy: 0.8092\n",
      "Epoch 23/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4884 - accuracy: 0.8395 - val_loss: 0.5747 - val_accuracy: 0.8244\n",
      "Epoch 24/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4706 - accuracy: 0.8460 - val_loss: 0.5679 - val_accuracy: 0.8244\n",
      "Epoch 25/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4763 - accuracy: 0.8390 - val_loss: 0.6310 - val_accuracy: 0.8136\n",
      "Epoch 26/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4676 - accuracy: 0.8400 - val_loss: 0.5644 - val_accuracy: 0.8321\n",
      "Epoch 27/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4578 - accuracy: 0.8481 - val_loss: 0.5717 - val_accuracy: 0.8263\n",
      "Epoch 28/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4323 - accuracy: 0.8659 - val_loss: 0.6028 - val_accuracy: 0.8232\n",
      "Epoch 29/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4261 - accuracy: 0.8603 - val_loss: 0.5798 - val_accuracy: 0.8276\n",
      "Epoch 30/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4343 - accuracy: 0.8591 - val_loss: 0.5797 - val_accuracy: 0.8212\n",
      "Epoch 31/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4124 - accuracy: 0.8651 - val_loss: 0.5670 - val_accuracy: 0.8340\n",
      "Epoch 32/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4055 - accuracy: 0.8681 - val_loss: 0.6324 - val_accuracy: 0.8257\n",
      "Epoch 33/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4136 - accuracy: 0.8700 - val_loss: 0.5788 - val_accuracy: 0.8289\n",
      "Epoch 34/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4091 - accuracy: 0.8686 - val_loss: 0.6343 - val_accuracy: 0.8282\n",
      "Epoch 35/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3839 - accuracy: 0.8704 - val_loss: 0.6494 - val_accuracy: 0.8181\n",
      "Epoch 36/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3740 - accuracy: 0.8812 - val_loss: 0.5986 - val_accuracy: 0.8378\n",
      "Epoch 37/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3709 - accuracy: 0.8823 - val_loss: 0.5642 - val_accuracy: 0.8333\n",
      "Epoch 38/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3353 - accuracy: 0.8910 - val_loss: 0.5824 - val_accuracy: 0.8378\n",
      "Epoch 39/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3419 - accuracy: 0.8910 - val_loss: 0.6276 - val_accuracy: 0.8333\n",
      "Epoch 40/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3522 - accuracy: 0.8863 - val_loss: 0.6321 - val_accuracy: 0.8219\n",
      "Epoch 41/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3478 - accuracy: 0.8874 - val_loss: 0.6192 - val_accuracy: 0.8302\n",
      "Epoch 42/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3291 - accuracy: 0.8990 - val_loss: 0.5924 - val_accuracy: 0.8346\n",
      "Epoch 43/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3373 - accuracy: 0.8930 - val_loss: 0.5863 - val_accuracy: 0.8384\n",
      "Epoch 44/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3329 - accuracy: 0.8976 - val_loss: 0.5852 - val_accuracy: 0.8467\n",
      "Epoch 45/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3369 - accuracy: 0.8949 - val_loss: 0.6302 - val_accuracy: 0.8352\n",
      "Epoch 46/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.2989 - accuracy: 0.9090 - val_loss: 0.6719 - val_accuracy: 0.8225\n",
      "Epoch 47/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3312 - accuracy: 0.8996 - val_loss: 0.6697 - val_accuracy: 0.8289\n",
      "Epoch 48/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3272 - accuracy: 0.9027 - val_loss: 0.6522 - val_accuracy: 0.8308\n",
      "Epoch 49/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3230 - accuracy: 0.9070 - val_loss: 0.7200 - val_accuracy: 0.8244\n",
      "Epoch 50/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.3093 - accuracy: 0.9044 - val_loss: 0.6289 - val_accuracy: 0.8333\n",
      "Fold 1: Test Loss = 4.4141, Test Accuracy = 0.4525\n",
      "Epoch 1/50\n",
      "197/197 [==============================] - 3s 11ms/step - loss: 1.8592 - accuracy: 0.3959 - val_loss: 1.2974 - val_accuracy: 0.5590\n",
      "Epoch 2/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 1.4593 - accuracy: 0.5122 - val_loss: 1.1090 - val_accuracy: 0.6310\n",
      "Epoch 3/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 1.2950 - accuracy: 0.5595 - val_loss: 1.0409 - val_accuracy: 0.6584\n",
      "Epoch 4/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 1.1972 - accuracy: 0.5979 - val_loss: 0.9338 - val_accuracy: 0.6928\n",
      "Epoch 5/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 1.0732 - accuracy: 0.6376 - val_loss: 0.9072 - val_accuracy: 0.6953\n",
      "Epoch 6/50\n",
      "197/197 [==============================] - 2s 12ms/step - loss: 0.9979 - accuracy: 0.6606 - val_loss: 0.8724 - val_accuracy: 0.7228\n",
      "Epoch 7/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.9463 - accuracy: 0.6747 - val_loss: 0.8242 - val_accuracy: 0.7368\n",
      "Epoch 8/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.8775 - accuracy: 0.7022 - val_loss: 0.8001 - val_accuracy: 0.7457\n",
      "Epoch 9/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.8332 - accuracy: 0.7175 - val_loss: 0.7342 - val_accuracy: 0.7527\n",
      "Epoch 10/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.8062 - accuracy: 0.7335 - val_loss: 0.6861 - val_accuracy: 0.7661\n",
      "Epoch 11/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.7512 - accuracy: 0.7425 - val_loss: 0.7024 - val_accuracy: 0.7725\n",
      "Epoch 12/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.7060 - accuracy: 0.7681 - val_loss: 0.6997 - val_accuracy: 0.7948\n",
      "Epoch 13/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.7050 - accuracy: 0.7643 - val_loss: 0.6743 - val_accuracy: 0.7706\n",
      "Epoch 14/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.6805 - accuracy: 0.7724 - val_loss: 0.6176 - val_accuracy: 0.7884\n",
      "Epoch 15/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.6319 - accuracy: 0.7879 - val_loss: 0.6450 - val_accuracy: 0.7941\n",
      "Epoch 16/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.6500 - accuracy: 0.7836 - val_loss: 0.6424 - val_accuracy: 0.7871\n",
      "Epoch 17/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.6038 - accuracy: 0.7998 - val_loss: 0.6447 - val_accuracy: 0.7929\n",
      "Epoch 18/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.5645 - accuracy: 0.8096 - val_loss: 0.5967 - val_accuracy: 0.8024\n",
      "Epoch 19/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.5720 - accuracy: 0.8131 - val_loss: 0.6095 - val_accuracy: 0.8050\n",
      "Epoch 20/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.5556 - accuracy: 0.8148 - val_loss: 0.5776 - val_accuracy: 0.8120\n",
      "Epoch 21/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.5163 - accuracy: 0.8269 - val_loss: 0.6587 - val_accuracy: 0.8056\n",
      "Epoch 22/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.5154 - accuracy: 0.8322 - val_loss: 0.6338 - val_accuracy: 0.7992\n",
      "Epoch 23/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.5003 - accuracy: 0.8398 - val_loss: 0.5798 - val_accuracy: 0.8107\n",
      "Epoch 24/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.5037 - accuracy: 0.8346 - val_loss: 0.5807 - val_accuracy: 0.8126\n",
      "Epoch 25/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4604 - accuracy: 0.8500 - val_loss: 0.5993 - val_accuracy: 0.8133\n",
      "Epoch 26/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4921 - accuracy: 0.8398 - val_loss: 0.6405 - val_accuracy: 0.7941\n",
      "Epoch 27/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4709 - accuracy: 0.8475 - val_loss: 0.6197 - val_accuracy: 0.8056\n",
      "Epoch 28/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4618 - accuracy: 0.8478 - val_loss: 0.5800 - val_accuracy: 0.8190\n",
      "Epoch 29/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4597 - accuracy: 0.8454 - val_loss: 0.6246 - val_accuracy: 0.8037\n",
      "Epoch 30/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4432 - accuracy: 0.8575 - val_loss: 0.6144 - val_accuracy: 0.8184\n",
      "Epoch 31/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4331 - accuracy: 0.8647 - val_loss: 0.6407 - val_accuracy: 0.8082\n",
      "Epoch 32/50\n",
      "197/197 [==============================] - 2s 11ms/step - loss: 0.4029 - accuracy: 0.8652 - val_loss: 0.5978 - val_accuracy: 0.8228\n",
      "Epoch 33/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4191 - accuracy: 0.8669 - val_loss: 0.6621 - val_accuracy: 0.8113\n",
      "Epoch 34/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4003 - accuracy: 0.8679 - val_loss: 0.6417 - val_accuracy: 0.8101\n",
      "Epoch 35/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3847 - accuracy: 0.8768 - val_loss: 0.6322 - val_accuracy: 0.8139\n",
      "Epoch 36/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3614 - accuracy: 0.8830 - val_loss: 0.6153 - val_accuracy: 0.8286\n",
      "Epoch 37/50\n",
      "197/197 [==============================] - 2s 9ms/step - loss: 0.3472 - accuracy: 0.8891 - val_loss: 0.6857 - val_accuracy: 0.8171\n",
      "Epoch 38/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.4097 - accuracy: 0.8719 - val_loss: 0.6106 - val_accuracy: 0.8164\n",
      "Epoch 39/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3696 - accuracy: 0.8795 - val_loss: 0.6075 - val_accuracy: 0.8177\n",
      "Epoch 40/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3490 - accuracy: 0.8878 - val_loss: 0.6382 - val_accuracy: 0.8196\n",
      "Epoch 41/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3652 - accuracy: 0.8865 - val_loss: 0.6428 - val_accuracy: 0.8107\n",
      "Epoch 42/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3430 - accuracy: 0.8932 - val_loss: 0.6281 - val_accuracy: 0.8164\n",
      "Epoch 43/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3795 - accuracy: 0.8787 - val_loss: 0.7423 - val_accuracy: 0.8062\n",
      "Epoch 44/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3266 - accuracy: 0.8950 - val_loss: 0.6566 - val_accuracy: 0.8337\n",
      "Epoch 45/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3685 - accuracy: 0.8875 - val_loss: 0.6715 - val_accuracy: 0.8286\n",
      "Epoch 46/50\n",
      "197/197 [==============================] - 2s 10ms/step - loss: 0.3437 - accuracy: 0.8921 - val_loss: 0.6138 - val_accuracy: 0.8273\n",
      "Epoch 47/50\n",
      "197/197 [==============================] - 3s 13ms/step - loss: 0.3023 - accuracy: 0.8982 - val_loss: 0.6871 - val_accuracy: 0.8190\n",
      "Epoch 48/50\n",
      "197/197 [==============================] - 2s 13ms/step - loss: 0.3551 - accuracy: 0.8886 - val_loss: 0.6097 - val_accuracy: 0.8254\n",
      "Epoch 49/50\n",
      "197/197 [==============================] - 2s 13ms/step - loss: 0.3033 - accuracy: 0.9079 - val_loss: 0.6801 - val_accuracy: 0.8196\n",
      "Epoch 50/50\n",
      "197/197 [==============================] - 3s 15ms/step - loss: 0.3232 - accuracy: 0.9026 - val_loss: 0.6949 - val_accuracy: 0.8324\n",
      "Fold 2: Test Loss = 4.2783, Test Accuracy = 0.4471\n",
      "Epoch 1/50\n",
      "196/196 [==============================] - 3s 11ms/step - loss: 1.8945 - accuracy: 0.3995 - val_loss: 1.2471 - val_accuracy: 0.6012\n",
      "Epoch 2/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.4674 - accuracy: 0.5023 - val_loss: 1.0568 - val_accuracy: 0.6402\n",
      "Epoch 3/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.3033 - accuracy: 0.5664 - val_loss: 0.9856 - val_accuracy: 0.6831\n",
      "Epoch 4/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.1677 - accuracy: 0.6075 - val_loss: 0.9078 - val_accuracy: 0.7049\n",
      "Epoch 5/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 1.0770 - accuracy: 0.6346 - val_loss: 0.8210 - val_accuracy: 0.7350\n",
      "Epoch 6/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.9847 - accuracy: 0.6639 - val_loss: 0.7748 - val_accuracy: 0.7516\n",
      "Epoch 7/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.9210 - accuracy: 0.6916 - val_loss: 0.7163 - val_accuracy: 0.7574\n",
      "Epoch 8/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.8779 - accuracy: 0.7092 - val_loss: 0.7167 - val_accuracy: 0.7580\n",
      "Epoch 9/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.8445 - accuracy: 0.7159 - val_loss: 0.6909 - val_accuracy: 0.7887\n",
      "Epoch 10/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.8044 - accuracy: 0.7276 - val_loss: 0.6666 - val_accuracy: 0.7766\n",
      "Epoch 11/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.7638 - accuracy: 0.7473 - val_loss: 0.6904 - val_accuracy: 0.7785\n",
      "Epoch 12/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.7305 - accuracy: 0.7569 - val_loss: 0.6324 - val_accuracy: 0.7971\n",
      "Epoch 13/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.6761 - accuracy: 0.7769 - val_loss: 0.6108 - val_accuracy: 0.7875\n",
      "Epoch 14/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.6672 - accuracy: 0.7809 - val_loss: 0.5973 - val_accuracy: 0.8124\n",
      "Epoch 15/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.6366 - accuracy: 0.7882 - val_loss: 0.6126 - val_accuracy: 0.7951\n",
      "Epoch 16/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.6385 - accuracy: 0.7856 - val_loss: 0.5982 - val_accuracy: 0.7932\n",
      "Epoch 17/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.5888 - accuracy: 0.8064 - val_loss: 0.6091 - val_accuracy: 0.8169\n",
      "Epoch 18/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.5739 - accuracy: 0.8101 - val_loss: 0.5467 - val_accuracy: 0.8137\n",
      "Epoch 19/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.5949 - accuracy: 0.8014 - val_loss: 0.5837 - val_accuracy: 0.8086\n",
      "Epoch 20/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.5276 - accuracy: 0.8224 - val_loss: 0.5697 - val_accuracy: 0.8143\n",
      "Epoch 21/50\n",
      "196/196 [==============================] - 3s 13ms/step - loss: 0.5347 - accuracy: 0.8267 - val_loss: 0.5696 - val_accuracy: 0.8220\n",
      "Epoch 22/50\n",
      "196/196 [==============================] - 2s 12ms/step - loss: 0.4868 - accuracy: 0.8424 - val_loss: 0.5588 - val_accuracy: 0.8195\n",
      "Epoch 23/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.5221 - accuracy: 0.8282 - val_loss: 0.5462 - val_accuracy: 0.8182\n",
      "Epoch 24/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.4818 - accuracy: 0.8368 - val_loss: 0.5679 - val_accuracy: 0.8259\n",
      "Epoch 25/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.5026 - accuracy: 0.8362 - val_loss: 0.5906 - val_accuracy: 0.8201\n",
      "Epoch 26/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.4404 - accuracy: 0.8535 - val_loss: 0.5964 - val_accuracy: 0.8220\n",
      "Epoch 27/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.4385 - accuracy: 0.8530 - val_loss: 0.5747 - val_accuracy: 0.8271\n",
      "Epoch 28/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.4828 - accuracy: 0.8431 - val_loss: 0.5795 - val_accuracy: 0.8316\n",
      "Epoch 29/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.4548 - accuracy: 0.8546 - val_loss: 0.5970 - val_accuracy: 0.8271\n",
      "Epoch 30/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.4400 - accuracy: 0.8592 - val_loss: 0.6141 - val_accuracy: 0.8246\n",
      "Epoch 31/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.4169 - accuracy: 0.8641 - val_loss: 0.5744 - val_accuracy: 0.8207\n",
      "Epoch 32/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.4076 - accuracy: 0.8706 - val_loss: 0.6266 - val_accuracy: 0.8137\n",
      "Epoch 33/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.4371 - accuracy: 0.8706 - val_loss: 0.5568 - val_accuracy: 0.8355\n",
      "Epoch 34/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.4053 - accuracy: 0.8665 - val_loss: 0.5448 - val_accuracy: 0.8399\n",
      "Epoch 35/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3872 - accuracy: 0.8762 - val_loss: 0.5558 - val_accuracy: 0.8323\n",
      "Epoch 36/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3974 - accuracy: 0.8717 - val_loss: 0.5545 - val_accuracy: 0.8291\n",
      "Epoch 37/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3803 - accuracy: 0.8765 - val_loss: 0.5870 - val_accuracy: 0.8201\n",
      "Epoch 38/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3536 - accuracy: 0.8887 - val_loss: 0.5590 - val_accuracy: 0.8323\n",
      "Epoch 39/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3899 - accuracy: 0.8765 - val_loss: 0.5740 - val_accuracy: 0.8303\n",
      "Epoch 40/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3691 - accuracy: 0.8791 - val_loss: 0.5562 - val_accuracy: 0.8374\n",
      "Epoch 41/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3717 - accuracy: 0.8817 - val_loss: 0.6133 - val_accuracy: 0.8323\n",
      "Epoch 42/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3549 - accuracy: 0.8876 - val_loss: 0.6918 - val_accuracy: 0.8175\n",
      "Epoch 43/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.3470 - accuracy: 0.8873 - val_loss: 0.6112 - val_accuracy: 0.8342\n",
      "Epoch 44/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.3473 - accuracy: 0.8916 - val_loss: 0.6151 - val_accuracy: 0.8195\n",
      "Epoch 45/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3520 - accuracy: 0.8881 - val_loss: 0.5850 - val_accuracy: 0.8361\n",
      "Epoch 46/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.3233 - accuracy: 0.8983 - val_loss: 0.5794 - val_accuracy: 0.8348\n",
      "Epoch 47/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3018 - accuracy: 0.9057 - val_loss: 0.6303 - val_accuracy: 0.8227\n",
      "Epoch 48/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.3305 - accuracy: 0.8972 - val_loss: 0.5710 - val_accuracy: 0.8335\n",
      "Epoch 49/50\n",
      "196/196 [==============================] - 2s 10ms/step - loss: 0.2913 - accuracy: 0.9068 - val_loss: 0.6048 - val_accuracy: 0.8335\n",
      "Epoch 50/50\n",
      "196/196 [==============================] - 2s 11ms/step - loss: 0.3127 - accuracy: 0.9054 - val_loss: 0.6169 - val_accuracy: 0.8316\n",
      "Fold 3: Test Loss = 3.0866, Test Accuracy = 0.4108\n",
      "Epoch 1/50\n",
      "194/194 [==============================] - 3s 11ms/step - loss: 1.8677 - accuracy: 0.3921 - val_loss: 1.2926 - val_accuracy: 0.5604\n",
      "Epoch 2/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 1.4657 - accuracy: 0.4962 - val_loss: 1.1342 - val_accuracy: 0.6372\n",
      "Epoch 3/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 1.3032 - accuracy: 0.5500 - val_loss: 1.0457 - val_accuracy: 0.6391\n",
      "Epoch 4/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 1.1750 - accuracy: 0.5936 - val_loss: 0.9655 - val_accuracy: 0.7024\n",
      "Epoch 5/50\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 1.0964 - accuracy: 0.6194 - val_loss: 0.9226 - val_accuracy: 0.6908\n",
      "Epoch 6/50\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 1.0151 - accuracy: 0.6523 - val_loss: 0.8977 - val_accuracy: 0.6946\n",
      "Epoch 7/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.9609 - accuracy: 0.6680 - val_loss: 0.8281 - val_accuracy: 0.7379\n",
      "Epoch 8/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.9084 - accuracy: 0.6822 - val_loss: 0.8009 - val_accuracy: 0.7295\n",
      "Epoch 9/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.8186 - accuracy: 0.7184 - val_loss: 0.7072 - val_accuracy: 0.7605\n",
      "Epoch 10/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.8012 - accuracy: 0.7260 - val_loss: 0.7498 - val_accuracy: 0.7624\n",
      "Epoch 11/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.7704 - accuracy: 0.7378 - val_loss: 0.6767 - val_accuracy: 0.7734\n",
      "Epoch 12/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.7478 - accuracy: 0.7431 - val_loss: 0.6799 - val_accuracy: 0.7799\n",
      "Epoch 13/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.7122 - accuracy: 0.7638 - val_loss: 0.6764 - val_accuracy: 0.7708\n",
      "Epoch 14/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.6775 - accuracy: 0.7647 - val_loss: 0.6559 - val_accuracy: 0.7992\n",
      "Epoch 15/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.6695 - accuracy: 0.7725 - val_loss: 0.6409 - val_accuracy: 0.7850\n",
      "Epoch 16/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.6189 - accuracy: 0.7890 - val_loss: 0.6559 - val_accuracy: 0.7915\n",
      "Epoch 17/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.6325 - accuracy: 0.7917 - val_loss: 0.6630 - val_accuracy: 0.7986\n",
      "Epoch 18/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.6188 - accuracy: 0.7893 - val_loss: 0.6020 - val_accuracy: 0.7999\n",
      "Epoch 19/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.5599 - accuracy: 0.8056 - val_loss: 0.5960 - val_accuracy: 0.8128\n",
      "Epoch 20/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.5524 - accuracy: 0.8166 - val_loss: 0.6303 - val_accuracy: 0.7966\n",
      "Epoch 21/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.5393 - accuracy: 0.8175 - val_loss: 0.5625 - val_accuracy: 0.8089\n",
      "Epoch 22/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.5294 - accuracy: 0.8196 - val_loss: 0.6267 - val_accuracy: 0.7992\n",
      "Epoch 23/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.5051 - accuracy: 0.8317 - val_loss: 0.5784 - val_accuracy: 0.8179\n",
      "Epoch 24/50\n",
      "194/194 [==============================] - 2s 12ms/step - loss: 0.5204 - accuracy: 0.8251 - val_loss: 0.5426 - val_accuracy: 0.8179\n",
      "Epoch 25/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.4875 - accuracy: 0.8382 - val_loss: 0.5953 - val_accuracy: 0.8167\n",
      "Epoch 26/50\n",
      "194/194 [==============================] - 2s 12ms/step - loss: 0.4729 - accuracy: 0.8424 - val_loss: 0.5973 - val_accuracy: 0.8141\n",
      "Epoch 27/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.4747 - accuracy: 0.8422 - val_loss: 0.5872 - val_accuracy: 0.8199\n",
      "Epoch 28/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.4741 - accuracy: 0.8476 - val_loss: 0.6335 - val_accuracy: 0.8031\n",
      "Epoch 29/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.4435 - accuracy: 0.8492 - val_loss: 0.6114 - val_accuracy: 0.8121\n",
      "Epoch 30/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.4439 - accuracy: 0.8582 - val_loss: 0.6193 - val_accuracy: 0.8154\n",
      "Epoch 31/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.4486 - accuracy: 0.8571 - val_loss: 0.6129 - val_accuracy: 0.8192\n",
      "Epoch 32/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.4458 - accuracy: 0.8566 - val_loss: 0.5740 - val_accuracy: 0.8167\n",
      "Epoch 33/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.4281 - accuracy: 0.8606 - val_loss: 0.5869 - val_accuracy: 0.8212\n",
      "Epoch 34/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.4196 - accuracy: 0.8629 - val_loss: 0.5879 - val_accuracy: 0.8218\n",
      "Epoch 35/50\n",
      "194/194 [==============================] - 2s 9ms/step - loss: 0.3967 - accuracy: 0.8700 - val_loss: 0.5758 - val_accuracy: 0.8192\n",
      "Epoch 36/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.3819 - accuracy: 0.8755 - val_loss: 0.6021 - val_accuracy: 0.8231\n",
      "Epoch 37/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.3671 - accuracy: 0.8813 - val_loss: 0.6191 - val_accuracy: 0.8160\n",
      "Epoch 38/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.3536 - accuracy: 0.8805 - val_loss: 0.6063 - val_accuracy: 0.8205\n",
      "Epoch 39/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.3855 - accuracy: 0.8826 - val_loss: 0.5815 - val_accuracy: 0.8321\n",
      "Epoch 40/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.3770 - accuracy: 0.8816 - val_loss: 0.5798 - val_accuracy: 0.8263\n",
      "Epoch 41/50\n",
      "194/194 [==============================] - 2s 12ms/step - loss: 0.3131 - accuracy: 0.8991 - val_loss: 0.6283 - val_accuracy: 0.8386\n",
      "Epoch 42/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.3760 - accuracy: 0.8841 - val_loss: 0.5998 - val_accuracy: 0.8302\n",
      "Epoch 43/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.3697 - accuracy: 0.8876 - val_loss: 0.5741 - val_accuracy: 0.8367\n",
      "Epoch 44/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.3752 - accuracy: 0.8862 - val_loss: 0.5511 - val_accuracy: 0.8418\n",
      "Epoch 45/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.3263 - accuracy: 0.8984 - val_loss: 0.6019 - val_accuracy: 0.8296\n",
      "Epoch 46/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.3471 - accuracy: 0.8931 - val_loss: 0.5776 - val_accuracy: 0.8289\n",
      "Epoch 47/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.2884 - accuracy: 0.9054 - val_loss: 0.5736 - val_accuracy: 0.8470\n",
      "Epoch 48/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.3016 - accuracy: 0.9000 - val_loss: 0.6065 - val_accuracy: 0.8238\n",
      "Epoch 49/50\n",
      "194/194 [==============================] - 2s 11ms/step - loss: 0.3291 - accuracy: 0.8963 - val_loss: 0.6190 - val_accuracy: 0.8257\n",
      "Epoch 50/50\n",
      "194/194 [==============================] - 2s 10ms/step - loss: 0.3021 - accuracy: 0.9046 - val_loss: 0.6264 - val_accuracy: 0.8321\n",
      "Fold 4: Test Loss = 3.2100, Test Accuracy = 0.4828\n",
      "Epoch 1/50\n",
      "195/195 [==============================] - 3s 10ms/step - loss: 1.8920 - accuracy: 0.3969 - val_loss: 1.2543 - val_accuracy: 0.5929\n",
      "Epoch 2/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 1.5021 - accuracy: 0.4889 - val_loss: 1.1558 - val_accuracy: 0.6269\n",
      "Epoch 3/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 1.3322 - accuracy: 0.5455 - val_loss: 1.0075 - val_accuracy: 0.6769\n",
      "Epoch 4/50\n",
      "195/195 [==============================] - 2s 13ms/step - loss: 1.1874 - accuracy: 0.5868 - val_loss: 0.9428 - val_accuracy: 0.6891\n",
      "Epoch 5/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 1.1033 - accuracy: 0.6244 - val_loss: 0.8771 - val_accuracy: 0.7186\n",
      "Epoch 6/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 1.0293 - accuracy: 0.6515 - val_loss: 0.8414 - val_accuracy: 0.7340\n",
      "Epoch 7/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.9632 - accuracy: 0.6796 - val_loss: 0.8153 - val_accuracy: 0.7372\n",
      "Epoch 8/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.8900 - accuracy: 0.6944 - val_loss: 0.8288 - val_accuracy: 0.7308\n",
      "Epoch 9/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.8703 - accuracy: 0.7041 - val_loss: 0.7575 - val_accuracy: 0.7654\n",
      "Epoch 10/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.7944 - accuracy: 0.7352 - val_loss: 0.7327 - val_accuracy: 0.7699\n",
      "Epoch 11/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.7652 - accuracy: 0.7397 - val_loss: 0.7047 - val_accuracy: 0.7609\n",
      "Epoch 12/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.7612 - accuracy: 0.7508 - val_loss: 0.6739 - val_accuracy: 0.7878\n",
      "Epoch 13/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.7173 - accuracy: 0.7559 - val_loss: 0.6781 - val_accuracy: 0.7801\n",
      "Epoch 14/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.6483 - accuracy: 0.7826 - val_loss: 0.6329 - val_accuracy: 0.7942\n",
      "Epoch 15/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.6737 - accuracy: 0.7750 - val_loss: 0.6428 - val_accuracy: 0.8013\n",
      "Epoch 16/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.6578 - accuracy: 0.7749 - val_loss: 0.6343 - val_accuracy: 0.8019\n",
      "Epoch 17/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.6059 - accuracy: 0.7968 - val_loss: 0.6160 - val_accuracy: 0.8045\n",
      "Epoch 18/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.6015 - accuracy: 0.8010 - val_loss: 0.6316 - val_accuracy: 0.7994\n",
      "Epoch 19/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.5870 - accuracy: 0.8044 - val_loss: 0.6001 - val_accuracy: 0.8071\n",
      "Epoch 20/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.5400 - accuracy: 0.8241 - val_loss: 0.6349 - val_accuracy: 0.8064\n",
      "Epoch 21/50\n",
      "195/195 [==============================] - 2s 13ms/step - loss: 0.5488 - accuracy: 0.8202 - val_loss: 0.6591 - val_accuracy: 0.8058\n",
      "Epoch 22/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.5478 - accuracy: 0.8233 - val_loss: 0.6284 - val_accuracy: 0.8090\n",
      "Epoch 23/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.5311 - accuracy: 0.8191 - val_loss: 0.5852 - val_accuracy: 0.8167\n",
      "Epoch 24/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.4954 - accuracy: 0.8300 - val_loss: 0.5644 - val_accuracy: 0.8276\n",
      "Epoch 25/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.4851 - accuracy: 0.8398 - val_loss: 0.5939 - val_accuracy: 0.8167\n",
      "Epoch 26/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.4786 - accuracy: 0.8432 - val_loss: 0.6039 - val_accuracy: 0.8192\n",
      "Epoch 27/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.4554 - accuracy: 0.8555 - val_loss: 0.5986 - val_accuracy: 0.8160\n",
      "Epoch 28/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.4660 - accuracy: 0.8501 - val_loss: 0.6582 - val_accuracy: 0.8013\n",
      "Epoch 29/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.4656 - accuracy: 0.8438 - val_loss: 0.6416 - val_accuracy: 0.8237\n",
      "Epoch 30/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.4459 - accuracy: 0.8501 - val_loss: 0.6342 - val_accuracy: 0.8141\n",
      "Epoch 31/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.4847 - accuracy: 0.8461 - val_loss: 0.6231 - val_accuracy: 0.8218\n",
      "Epoch 32/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.4260 - accuracy: 0.8623 - val_loss: 0.5815 - val_accuracy: 0.8308\n",
      "Epoch 33/50\n",
      "195/195 [==============================] - 3s 14ms/step - loss: 0.3785 - accuracy: 0.8691 - val_loss: 0.6438 - val_accuracy: 0.8167\n",
      "Epoch 34/50\n",
      "195/195 [==============================] - 3s 13ms/step - loss: 0.3999 - accuracy: 0.8756 - val_loss: 0.6240 - val_accuracy: 0.8250\n",
      "Epoch 35/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.3797 - accuracy: 0.8749 - val_loss: 0.6572 - val_accuracy: 0.8212\n",
      "Epoch 36/50\n",
      "195/195 [==============================] - 3s 13ms/step - loss: 0.4151 - accuracy: 0.8703 - val_loss: 0.6247 - val_accuracy: 0.8186\n",
      "Epoch 37/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.3802 - accuracy: 0.8825 - val_loss: 0.6902 - val_accuracy: 0.8109\n",
      "Epoch 38/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.3764 - accuracy: 0.8781 - val_loss: 0.6958 - val_accuracy: 0.8045\n",
      "Epoch 39/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.3663 - accuracy: 0.8863 - val_loss: 0.7333 - val_accuracy: 0.8026\n",
      "Epoch 40/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.3785 - accuracy: 0.8780 - val_loss: 0.6662 - val_accuracy: 0.8160\n",
      "Epoch 41/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.3718 - accuracy: 0.8828 - val_loss: 0.6326 - val_accuracy: 0.8276\n",
      "Epoch 42/50\n",
      "195/195 [==============================] - 3s 14ms/step - loss: 0.3585 - accuracy: 0.8903 - val_loss: 0.6322 - val_accuracy: 0.8250\n",
      "Epoch 43/50\n",
      "195/195 [==============================] - 3s 14ms/step - loss: 0.3482 - accuracy: 0.8932 - val_loss: 0.6509 - val_accuracy: 0.8250\n",
      "Epoch 44/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.3205 - accuracy: 0.8977 - val_loss: 0.6794 - val_accuracy: 0.8160\n",
      "Epoch 45/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.3196 - accuracy: 0.9023 - val_loss: 0.7070 - val_accuracy: 0.8276\n",
      "Epoch 46/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.3645 - accuracy: 0.8914 - val_loss: 0.6865 - val_accuracy: 0.8135\n",
      "Epoch 47/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.3203 - accuracy: 0.9020 - val_loss: 0.6129 - val_accuracy: 0.8365\n",
      "Epoch 48/50\n",
      "195/195 [==============================] - 2s 12ms/step - loss: 0.3144 - accuracy: 0.9065 - val_loss: 0.6573 - val_accuracy: 0.8244\n",
      "Epoch 49/50\n",
      "195/195 [==============================] - 2s 11ms/step - loss: 0.2901 - accuracy: 0.9075 - val_loss: 0.7076 - val_accuracy: 0.8321\n",
      "Epoch 50/50\n",
      "195/195 [==============================] - 2s 10ms/step - loss: 0.3065 - accuracy: 0.9081 - val_loss: 0.5831 - val_accuracy: 0.8372\n",
      "Fold 5: Test Loss = 2.0072, Test Accuracy = 0.5662\n",
      "Epoch 1/50\n",
      "198/198 [==============================] - 3s 11ms/step - loss: 1.8650 - accuracy: 0.3997 - val_loss: 1.3642 - val_accuracy: 0.5702\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 1.4696 - accuracy: 0.5036 - val_loss: 1.1498 - val_accuracy: 0.6214\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 1.2979 - accuracy: 0.5565 - val_loss: 1.0250 - val_accuracy: 0.6568\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 1.2010 - accuracy: 0.5982 - val_loss: 0.9819 - val_accuracy: 0.6751\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 1.0920 - accuracy: 0.6278 - val_loss: 0.9049 - val_accuracy: 0.6915\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.9898 - accuracy: 0.6648 - val_loss: 0.8691 - val_accuracy: 0.7295\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.9410 - accuracy: 0.6829 - val_loss: 0.7981 - val_accuracy: 0.7396\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.8759 - accuracy: 0.7043 - val_loss: 0.7874 - val_accuracy: 0.7440\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.8072 - accuracy: 0.7278 - val_loss: 0.7612 - val_accuracy: 0.7623\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.8099 - accuracy: 0.7272 - val_loss: 0.7641 - val_accuracy: 0.7528\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.7577 - accuracy: 0.7459 - val_loss: 0.7365 - val_accuracy: 0.7611\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.7363 - accuracy: 0.7531 - val_loss: 0.7044 - val_accuracy: 0.7775\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.6873 - accuracy: 0.7656 - val_loss: 0.6986 - val_accuracy: 0.7642\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.6304 - accuracy: 0.7849 - val_loss: 0.6752 - val_accuracy: 0.7863\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.6548 - accuracy: 0.7876 - val_loss: 0.6787 - val_accuracy: 0.7756\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.6423 - accuracy: 0.7813 - val_loss: 0.6913 - val_accuracy: 0.7686\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.6356 - accuracy: 0.7918 - val_loss: 0.6523 - val_accuracy: 0.7965\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 2s 13ms/step - loss: 0.5622 - accuracy: 0.8086 - val_loss: 0.6844 - val_accuracy: 0.7857\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.5760 - accuracy: 0.8080 - val_loss: 0.6716 - val_accuracy: 0.7851\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.5449 - accuracy: 0.8156 - val_loss: 0.6687 - val_accuracy: 0.7958\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.5330 - accuracy: 0.8200 - val_loss: 0.6538 - val_accuracy: 0.8028\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.5103 - accuracy: 0.8293 - val_loss: 0.7223 - val_accuracy: 0.7933\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4789 - accuracy: 0.8419 - val_loss: 0.6959 - val_accuracy: 0.8053\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4889 - accuracy: 0.8363 - val_loss: 0.6779 - val_accuracy: 0.8066\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.4968 - accuracy: 0.8397 - val_loss: 0.6767 - val_accuracy: 0.8021\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.4530 - accuracy: 0.8522 - val_loss: 0.6699 - val_accuracy: 0.8009\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.4426 - accuracy: 0.8609 - val_loss: 0.6749 - val_accuracy: 0.7920\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4495 - accuracy: 0.8547 - val_loss: 0.6825 - val_accuracy: 0.7984\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.4051 - accuracy: 0.8674 - val_loss: 0.7047 - val_accuracy: 0.7901\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.4342 - accuracy: 0.8625 - val_loss: 0.6978 - val_accuracy: 0.8053\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.4007 - accuracy: 0.8704 - val_loss: 0.6614 - val_accuracy: 0.8123\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.3923 - accuracy: 0.8756 - val_loss: 0.7222 - val_accuracy: 0.7876\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.3873 - accuracy: 0.8750 - val_loss: 0.7360 - val_accuracy: 0.8053\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.3754 - accuracy: 0.8792 - val_loss: 0.6725 - val_accuracy: 0.8009\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.3773 - accuracy: 0.8805 - val_loss: 0.6832 - val_accuracy: 0.8135\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4024 - accuracy: 0.8762 - val_loss: 0.6943 - val_accuracy: 0.8110\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3670 - accuracy: 0.8849 - val_loss: 0.7052 - val_accuracy: 0.8167\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.3592 - accuracy: 0.8872 - val_loss: 0.6524 - val_accuracy: 0.8161\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3442 - accuracy: 0.8884 - val_loss: 0.6500 - val_accuracy: 0.8135\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3625 - accuracy: 0.8938 - val_loss: 0.7469 - val_accuracy: 0.8123\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3378 - accuracy: 0.8987 - val_loss: 0.7051 - val_accuracy: 0.7984\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3617 - accuracy: 0.8895 - val_loss: 0.6867 - val_accuracy: 0.8154\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3178 - accuracy: 0.9011 - val_loss: 0.6904 - val_accuracy: 0.8104\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3007 - accuracy: 0.9012 - val_loss: 0.7627 - val_accuracy: 0.8034\n",
      "Epoch 45/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 0.3424 - accuracy: 0.8958 - val_loss: 0.7370 - val_accuracy: 0.8135\n",
      "Epoch 46/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.3358 - accuracy: 0.8992 - val_loss: 0.7553 - val_accuracy: 0.8116\n",
      "Epoch 47/50\n",
      "198/198 [==============================] - 3s 14ms/step - loss: 0.2982 - accuracy: 0.9104 - val_loss: 0.7885 - val_accuracy: 0.8021\n",
      "Epoch 48/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.2969 - accuracy: 0.9088 - val_loss: 0.7438 - val_accuracy: 0.8066\n",
      "Epoch 49/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.2811 - accuracy: 0.9109 - val_loss: 0.7102 - val_accuracy: 0.8097\n",
      "Epoch 50/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.2842 - accuracy: 0.9153 - val_loss: 0.7044 - val_accuracy: 0.8167\n",
      "Fold 6: Test Loss = 2.4710, Test Accuracy = 0.4678\n",
      "Epoch 1/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 1.9326 - accuracy: 0.3769 - val_loss: 1.3215 - val_accuracy: 0.5662\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 1.4657 - accuracy: 0.5002 - val_loss: 1.1800 - val_accuracy: 0.6333\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 3s 13ms/step - loss: 1.3184 - accuracy: 0.5511 - val_loss: 1.0586 - val_accuracy: 0.6460\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 1.1994 - accuracy: 0.5892 - val_loss: 0.9960 - val_accuracy: 0.6821\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 1.0944 - accuracy: 0.6171 - val_loss: 0.9310 - val_accuracy: 0.7017\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 1.0304 - accuracy: 0.6510 - val_loss: 0.8612 - val_accuracy: 0.7340\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.9647 - accuracy: 0.6717 - val_loss: 0.8425 - val_accuracy: 0.7321\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.8890 - accuracy: 0.6958 - val_loss: 0.7815 - val_accuracy: 0.7511\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.8599 - accuracy: 0.6994 - val_loss: 0.8197 - val_accuracy: 0.7429\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.8214 - accuracy: 0.7229 - val_loss: 0.7560 - val_accuracy: 0.7606\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.7905 - accuracy: 0.7264 - val_loss: 0.7544 - val_accuracy: 0.7612\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.7227 - accuracy: 0.7517 - val_loss: 0.7132 - val_accuracy: 0.7809\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.7355 - accuracy: 0.7457 - val_loss: 0.7172 - val_accuracy: 0.7764\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.7021 - accuracy: 0.7647 - val_loss: 0.6760 - val_accuracy: 0.7992\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.6921 - accuracy: 0.7642 - val_loss: 0.7247 - val_accuracy: 0.7790\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.6836 - accuracy: 0.7644 - val_loss: 0.6740 - val_accuracy: 0.7992\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.6357 - accuracy: 0.7848 - val_loss: 0.6848 - val_accuracy: 0.7853\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.5958 - accuracy: 0.8006 - val_loss: 0.7247 - val_accuracy: 0.7929\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.5793 - accuracy: 0.8112 - val_loss: 0.6828 - val_accuracy: 0.7967\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.5714 - accuracy: 0.8057 - val_loss: 0.6732 - val_accuracy: 0.8094\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.5615 - accuracy: 0.8124 - val_loss: 0.7171 - val_accuracy: 0.7967\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.5602 - accuracy: 0.8155 - val_loss: 0.6693 - val_accuracy: 0.8049\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.5255 - accuracy: 0.8190 - val_loss: 0.6320 - val_accuracy: 0.8144\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.5282 - accuracy: 0.8293 - val_loss: 0.6167 - val_accuracy: 0.8239\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.5168 - accuracy: 0.8290 - val_loss: 0.6172 - val_accuracy: 0.8252\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4945 - accuracy: 0.8374 - val_loss: 0.6499 - val_accuracy: 0.8138\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4949 - accuracy: 0.8461 - val_loss: 0.6464 - val_accuracy: 0.8151\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.4561 - accuracy: 0.8459 - val_loss: 0.6463 - val_accuracy: 0.8163\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4254 - accuracy: 0.8625 - val_loss: 0.6312 - val_accuracy: 0.8277\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.4680 - accuracy: 0.8538 - val_loss: 0.6688 - val_accuracy: 0.8119\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 2s 12ms/step - loss: 0.4297 - accuracy: 0.8589 - val_loss: 0.6532 - val_accuracy: 0.8144\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4252 - accuracy: 0.8629 - val_loss: 0.6716 - val_accuracy: 0.8252\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3975 - accuracy: 0.8709 - val_loss: 0.6524 - val_accuracy: 0.8334\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3842 - accuracy: 0.8792 - val_loss: 0.6707 - val_accuracy: 0.8233\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.4114 - accuracy: 0.8740 - val_loss: 0.6956 - val_accuracy: 0.8258\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3856 - accuracy: 0.8740 - val_loss: 0.6491 - val_accuracy: 0.8195\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3965 - accuracy: 0.8752 - val_loss: 0.7062 - val_accuracy: 0.8176\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3656 - accuracy: 0.8835 - val_loss: 0.7190 - val_accuracy: 0.8087\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3956 - accuracy: 0.8804 - val_loss: 0.6949 - val_accuracy: 0.8322\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3777 - accuracy: 0.8793 - val_loss: 0.7354 - val_accuracy: 0.8151\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3732 - accuracy: 0.8801 - val_loss: 0.6648 - val_accuracy: 0.8265\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3278 - accuracy: 0.8941 - val_loss: 0.6972 - val_accuracy: 0.8303\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3535 - accuracy: 0.8893 - val_loss: 0.6963 - val_accuracy: 0.8233\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3321 - accuracy: 0.8944 - val_loss: 0.7336 - val_accuracy: 0.8220\n",
      "Epoch 45/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3760 - accuracy: 0.8890 - val_loss: 0.6855 - val_accuracy: 0.8290\n",
      "Epoch 46/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3275 - accuracy: 0.8960 - val_loss: 0.7420 - val_accuracy: 0.8353\n",
      "Epoch 47/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.3354 - accuracy: 0.8942 - val_loss: 0.7411 - val_accuracy: 0.8334\n",
      "Epoch 48/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3112 - accuracy: 0.9031 - val_loss: 0.7069 - val_accuracy: 0.8296\n",
      "Epoch 49/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3438 - accuracy: 0.8969 - val_loss: 0.7404 - val_accuracy: 0.8284\n",
      "Epoch 50/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3565 - accuracy: 0.8885 - val_loss: 0.7485 - val_accuracy: 0.8233\n",
      "Fold 7: Test Loss = 1.9377, Test Accuracy = 0.5740\n",
      "Epoch 1/50\n",
      "199/199 [==============================] - 3s 11ms/step - loss: 1.8938 - accuracy: 0.3864 - val_loss: 1.3061 - val_accuracy: 0.5523\n",
      "Epoch 2/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 1.4754 - accuracy: 0.4998 - val_loss: 1.1485 - val_accuracy: 0.6185\n",
      "Epoch 3/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 1.3103 - accuracy: 0.5563 - val_loss: 1.0183 - val_accuracy: 0.6538\n",
      "Epoch 4/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 1.1541 - accuracy: 0.6014 - val_loss: 0.9706 - val_accuracy: 0.6822\n",
      "Epoch 5/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 1.0648 - accuracy: 0.6374 - val_loss: 0.9119 - val_accuracy: 0.6904\n",
      "Epoch 6/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.9935 - accuracy: 0.6640 - val_loss: 0.8590 - val_accuracy: 0.7175\n",
      "Epoch 7/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.9204 - accuracy: 0.6847 - val_loss: 0.8113 - val_accuracy: 0.7308\n",
      "Epoch 8/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.9039 - accuracy: 0.6967 - val_loss: 0.8217 - val_accuracy: 0.7144\n",
      "Epoch 9/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.8138 - accuracy: 0.7207 - val_loss: 0.7773 - val_accuracy: 0.7396\n",
      "Epoch 10/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.7782 - accuracy: 0.7342 - val_loss: 0.7668 - val_accuracy: 0.7440\n",
      "Epoch 11/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.7945 - accuracy: 0.7379 - val_loss: 0.7429 - val_accuracy: 0.7535\n",
      "Epoch 12/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.7186 - accuracy: 0.7618 - val_loss: 0.7306 - val_accuracy: 0.7724\n",
      "Epoch 13/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.6876 - accuracy: 0.7678 - val_loss: 0.7754 - val_accuracy: 0.7503\n",
      "Epoch 14/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.6508 - accuracy: 0.7762 - val_loss: 0.6972 - val_accuracy: 0.7692\n",
      "Epoch 15/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.6410 - accuracy: 0.7798 - val_loss: 0.6663 - val_accuracy: 0.7749\n",
      "Epoch 16/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.5919 - accuracy: 0.7986 - val_loss: 0.7049 - val_accuracy: 0.7692\n",
      "Epoch 17/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.6018 - accuracy: 0.8008 - val_loss: 0.6664 - val_accuracy: 0.7888\n",
      "Epoch 18/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.5790 - accuracy: 0.8080 - val_loss: 0.6947 - val_accuracy: 0.7718\n",
      "Epoch 19/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.5662 - accuracy: 0.8109 - val_loss: 0.6588 - val_accuracy: 0.7850\n",
      "Epoch 20/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.5456 - accuracy: 0.8148 - val_loss: 0.6885 - val_accuracy: 0.7755\n",
      "Epoch 21/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.5252 - accuracy: 0.8210 - val_loss: 0.6379 - val_accuracy: 0.7932\n",
      "Epoch 22/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.4934 - accuracy: 0.8336 - val_loss: 0.6776 - val_accuracy: 0.7774\n",
      "Epoch 23/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.4647 - accuracy: 0.8443 - val_loss: 0.6770 - val_accuracy: 0.7900\n",
      "Epoch 24/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.5183 - accuracy: 0.8344 - val_loss: 0.6167 - val_accuracy: 0.7995\n",
      "Epoch 25/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.4829 - accuracy: 0.8415 - val_loss: 0.6758 - val_accuracy: 0.7831\n",
      "Epoch 26/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.4543 - accuracy: 0.8429 - val_loss: 0.6765 - val_accuracy: 0.7774\n",
      "Epoch 27/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.4499 - accuracy: 0.8574 - val_loss: 0.6879 - val_accuracy: 0.7963\n",
      "Epoch 28/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.4243 - accuracy: 0.8577 - val_loss: 0.6988 - val_accuracy: 0.8008\n",
      "Epoch 29/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.4355 - accuracy: 0.8642 - val_loss: 0.6646 - val_accuracy: 0.7976\n",
      "Epoch 30/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.4286 - accuracy: 0.8650 - val_loss: 0.7098 - val_accuracy: 0.7863\n",
      "Epoch 31/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.4218 - accuracy: 0.8662 - val_loss: 0.6532 - val_accuracy: 0.8045\n",
      "Epoch 32/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.4058 - accuracy: 0.8661 - val_loss: 0.6513 - val_accuracy: 0.7995\n",
      "Epoch 33/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.4149 - accuracy: 0.8732 - val_loss: 0.6509 - val_accuracy: 0.8064\n",
      "Epoch 34/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.4376 - accuracy: 0.8596 - val_loss: 0.6761 - val_accuracy: 0.7938\n",
      "Epoch 35/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.3888 - accuracy: 0.8726 - val_loss: 0.6301 - val_accuracy: 0.8108\n",
      "Epoch 36/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.3692 - accuracy: 0.8770 - val_loss: 0.6439 - val_accuracy: 0.8058\n",
      "Epoch 37/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.3581 - accuracy: 0.8845 - val_loss: 0.7200 - val_accuracy: 0.8134\n",
      "Epoch 38/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.3880 - accuracy: 0.8819 - val_loss: 0.7305 - val_accuracy: 0.7995\n",
      "Epoch 39/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.3904 - accuracy: 0.8814 - val_loss: 0.6496 - val_accuracy: 0.8096\n",
      "Epoch 40/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.3535 - accuracy: 0.8885 - val_loss: 0.7001 - val_accuracy: 0.8064\n",
      "Epoch 41/50\n",
      "199/199 [==============================] - 2s 12ms/step - loss: 0.3687 - accuracy: 0.8853 - val_loss: 0.7313 - val_accuracy: 0.8083\n",
      "Epoch 42/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.3329 - accuracy: 0.8978 - val_loss: 0.6777 - val_accuracy: 0.8127\n",
      "Epoch 43/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.3275 - accuracy: 0.8973 - val_loss: 0.6831 - val_accuracy: 0.8071\n",
      "Epoch 44/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.3626 - accuracy: 0.8896 - val_loss: 0.6359 - val_accuracy: 0.8146\n",
      "Epoch 45/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.3037 - accuracy: 0.9044 - val_loss: 0.7998 - val_accuracy: 0.8008\n",
      "Epoch 46/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.3561 - accuracy: 0.8934 - val_loss: 0.7478 - val_accuracy: 0.7995\n",
      "Epoch 47/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.3451 - accuracy: 0.8894 - val_loss: 0.7614 - val_accuracy: 0.8146\n",
      "Epoch 48/50\n",
      "199/199 [==============================] - 2s 10ms/step - loss: 0.3352 - accuracy: 0.8987 - val_loss: 0.7026 - val_accuracy: 0.8121\n",
      "Epoch 49/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.2870 - accuracy: 0.9107 - val_loss: 0.8108 - val_accuracy: 0.8026\n",
      "Epoch 50/50\n",
      "199/199 [==============================] - 2s 11ms/step - loss: 0.3187 - accuracy: 0.8995 - val_loss: 0.7317 - val_accuracy: 0.8115\n",
      "Fold 8: Test Loss = 2.2037, Test Accuracy = 0.5918\n",
      "Epoch 1/50\n",
      "198/198 [==============================] - 3s 10ms/step - loss: 1.8878 - accuracy: 0.3852 - val_loss: 1.3023 - val_accuracy: 0.5713\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 1.4647 - accuracy: 0.4959 - val_loss: 1.2131 - val_accuracy: 0.5909\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 1.3081 - accuracy: 0.5570 - val_loss: 1.0944 - val_accuracy: 0.6326\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 1.1881 - accuracy: 0.6031 - val_loss: 0.9808 - val_accuracy: 0.6768\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 1.0886 - accuracy: 0.6290 - val_loss: 0.9212 - val_accuracy: 0.6995\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 1.0100 - accuracy: 0.6586 - val_loss: 0.8669 - val_accuracy: 0.7052\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.9351 - accuracy: 0.6821 - val_loss: 0.8425 - val_accuracy: 0.7241\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.8894 - accuracy: 0.6966 - val_loss: 0.8426 - val_accuracy: 0.7146\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.8148 - accuracy: 0.7239 - val_loss: 0.7617 - val_accuracy: 0.7487\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.8174 - accuracy: 0.7262 - val_loss: 0.7694 - val_accuracy: 0.7393\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.7523 - accuracy: 0.7440 - val_loss: 0.7237 - val_accuracy: 0.7652\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.7445 - accuracy: 0.7522 - val_loss: 0.7207 - val_accuracy: 0.7664\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.7091 - accuracy: 0.7595 - val_loss: 0.7003 - val_accuracy: 0.7715\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.6477 - accuracy: 0.7800 - val_loss: 0.7055 - val_accuracy: 0.7847\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.6405 - accuracy: 0.7813 - val_loss: 0.6969 - val_accuracy: 0.7721\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.6224 - accuracy: 0.7912 - val_loss: 0.6743 - val_accuracy: 0.7790\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.6229 - accuracy: 0.7871 - val_loss: 0.7245 - val_accuracy: 0.7601\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.5797 - accuracy: 0.8009 - val_loss: 0.6911 - val_accuracy: 0.7854\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.5801 - accuracy: 0.8061 - val_loss: 0.7060 - val_accuracy: 0.7633\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.5469 - accuracy: 0.8173 - val_loss: 0.7144 - val_accuracy: 0.7828\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.5257 - accuracy: 0.8203 - val_loss: 0.6691 - val_accuracy: 0.7917\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.5010 - accuracy: 0.8321 - val_loss: 0.7130 - val_accuracy: 0.7828\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.5126 - accuracy: 0.8335 - val_loss: 0.7069 - val_accuracy: 0.7854\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.5425 - accuracy: 0.8249 - val_loss: 0.6671 - val_accuracy: 0.7841\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.4852 - accuracy: 0.8381 - val_loss: 0.7130 - val_accuracy: 0.7860\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.4977 - accuracy: 0.8356 - val_loss: 0.6884 - val_accuracy: 0.7929\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.4261 - accuracy: 0.8587 - val_loss: 0.6781 - val_accuracy: 0.7986\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.4131 - accuracy: 0.8632 - val_loss: 0.6512 - val_accuracy: 0.8037\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.4442 - accuracy: 0.8564 - val_loss: 0.6896 - val_accuracy: 0.7986\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4071 - accuracy: 0.8643 - val_loss: 0.7009 - val_accuracy: 0.7980\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4499 - accuracy: 0.8545 - val_loss: 0.6778 - val_accuracy: 0.8037\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 2s 11ms/step - loss: 0.4331 - accuracy: 0.8517 - val_loss: 0.6792 - val_accuracy: 0.7885\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.4023 - accuracy: 0.8667 - val_loss: 0.6785 - val_accuracy: 0.7986\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.4174 - accuracy: 0.8587 - val_loss: 0.6340 - val_accuracy: 0.8087\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3869 - accuracy: 0.8737 - val_loss: 0.6925 - val_accuracy: 0.8100\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3916 - accuracy: 0.8744 - val_loss: 0.7145 - val_accuracy: 0.8068\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3830 - accuracy: 0.8808 - val_loss: 0.6892 - val_accuracy: 0.7955\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3942 - accuracy: 0.8773 - val_loss: 0.6992 - val_accuracy: 0.8030\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3533 - accuracy: 0.8853 - val_loss: 0.6673 - val_accuracy: 0.8087\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3467 - accuracy: 0.8853 - val_loss: 0.7441 - val_accuracy: 0.8030\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3271 - accuracy: 0.9002 - val_loss: 0.7292 - val_accuracy: 0.8074\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3416 - accuracy: 0.8868 - val_loss: 0.7100 - val_accuracy: 0.8207\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3468 - accuracy: 0.8906 - val_loss: 0.6862 - val_accuracy: 0.7986\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3191 - accuracy: 0.8962 - val_loss: 0.8171 - val_accuracy: 0.7942\n",
      "Epoch 45/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3443 - accuracy: 0.8923 - val_loss: 0.7538 - val_accuracy: 0.7986\n",
      "Epoch 46/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3424 - accuracy: 0.8937 - val_loss: 0.7984 - val_accuracy: 0.7980\n",
      "Epoch 47/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3429 - accuracy: 0.8912 - val_loss: 0.7301 - val_accuracy: 0.8062\n",
      "Epoch 48/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.3234 - accuracy: 0.8973 - val_loss: 0.7498 - val_accuracy: 0.7961\n",
      "Epoch 49/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.2996 - accuracy: 0.9084 - val_loss: 0.7495 - val_accuracy: 0.8100\n",
      "Epoch 50/50\n",
      "198/198 [==============================] - 2s 10ms/step - loss: 0.2960 - accuracy: 0.9059 - val_loss: 0.7580 - val_accuracy: 0.8144\n",
      "Fold 9: Test Loss = 2.7672, Test Accuracy = 0.5858\n",
      "Epoch 1/50\n",
      "198/198 [==============================] - 3s 12ms/step - loss: 1.8730 - accuracy: 0.3946 - val_loss: 1.2613 - val_accuracy: 0.5814\n",
      "Epoch 2/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 1.4499 - accuracy: 0.5070 - val_loss: 1.1672 - val_accuracy: 0.6143\n",
      "Epoch 3/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 1.3062 - accuracy: 0.5600 - val_loss: 1.1007 - val_accuracy: 0.6396\n",
      "Epoch 4/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 1.1683 - accuracy: 0.6050 - val_loss: 1.0012 - val_accuracy: 0.6890\n",
      "Epoch 5/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 1.0839 - accuracy: 0.6257 - val_loss: 0.9000 - val_accuracy: 0.7182\n",
      "Epoch 6/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.9963 - accuracy: 0.6593 - val_loss: 0.8912 - val_accuracy: 0.7099\n",
      "Epoch 7/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.9301 - accuracy: 0.6821 - val_loss: 0.8571 - val_accuracy: 0.7201\n",
      "Epoch 8/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.8751 - accuracy: 0.6951 - val_loss: 0.8153 - val_accuracy: 0.7460\n",
      "Epoch 9/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.8484 - accuracy: 0.7087 - val_loss: 0.8434 - val_accuracy: 0.7441\n",
      "Epoch 10/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.8258 - accuracy: 0.7191 - val_loss: 0.8442 - val_accuracy: 0.7327\n",
      "Epoch 11/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.7935 - accuracy: 0.7348 - val_loss: 0.7759 - val_accuracy: 0.7492\n",
      "Epoch 12/50\n",
      "198/198 [==============================] - 4s 19ms/step - loss: 0.7275 - accuracy: 0.7432 - val_loss: 0.7705 - val_accuracy: 0.7631\n",
      "Epoch 13/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.7281 - accuracy: 0.7535 - val_loss: 0.7263 - val_accuracy: 0.7701\n",
      "Epoch 14/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.6893 - accuracy: 0.7649 - val_loss: 0.7452 - val_accuracy: 0.7631\n",
      "Epoch 15/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.6715 - accuracy: 0.7741 - val_loss: 0.7027 - val_accuracy: 0.7897\n",
      "Epoch 16/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.6324 - accuracy: 0.7837 - val_loss: 0.7223 - val_accuracy: 0.7834\n",
      "Epoch 17/50\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.6248 - accuracy: 0.7870 - val_loss: 0.7200 - val_accuracy: 0.7910\n",
      "Epoch 18/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.6185 - accuracy: 0.7907 - val_loss: 0.7457 - val_accuracy: 0.7720\n",
      "Epoch 19/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.6091 - accuracy: 0.7935 - val_loss: 0.7138 - val_accuracy: 0.7739\n",
      "Epoch 20/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.5677 - accuracy: 0.8064 - val_loss: 0.7058 - val_accuracy: 0.7840\n",
      "Epoch 21/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.5433 - accuracy: 0.8160 - val_loss: 0.6958 - val_accuracy: 0.7796\n",
      "Epoch 22/50\n",
      "198/198 [==============================] - 3s 18ms/step - loss: 0.5322 - accuracy: 0.8224 - val_loss: 0.6690 - val_accuracy: 0.8005\n",
      "Epoch 23/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.5329 - accuracy: 0.8235 - val_loss: 0.6994 - val_accuracy: 0.7980\n",
      "Epoch 24/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.5008 - accuracy: 0.8331 - val_loss: 0.6541 - val_accuracy: 0.8151\n",
      "Epoch 25/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.4958 - accuracy: 0.8363 - val_loss: 0.6793 - val_accuracy: 0.7910\n",
      "Epoch 26/50\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.4941 - accuracy: 0.8374 - val_loss: 0.7058 - val_accuracy: 0.7872\n",
      "Epoch 27/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.4765 - accuracy: 0.8391 - val_loss: 0.7219 - val_accuracy: 0.7980\n",
      "Epoch 28/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.4847 - accuracy: 0.8420 - val_loss: 0.7235 - val_accuracy: 0.7980\n",
      "Epoch 29/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.4785 - accuracy: 0.8414 - val_loss: 0.6999 - val_accuracy: 0.8011\n",
      "Epoch 30/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.4431 - accuracy: 0.8540 - val_loss: 0.7254 - val_accuracy: 0.8100\n",
      "Epoch 31/50\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.4415 - accuracy: 0.8562 - val_loss: 0.7573 - val_accuracy: 0.8163\n",
      "Epoch 32/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.4457 - accuracy: 0.8531 - val_loss: 0.7443 - val_accuracy: 0.8151\n",
      "Epoch 33/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.4233 - accuracy: 0.8608 - val_loss: 0.7177 - val_accuracy: 0.8239\n",
      "Epoch 34/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.4112 - accuracy: 0.8724 - val_loss: 0.7356 - val_accuracy: 0.8144\n",
      "Epoch 35/50\n",
      "198/198 [==============================] - 3s 18ms/step - loss: 0.4273 - accuracy: 0.8643 - val_loss: 0.7320 - val_accuracy: 0.8037\n",
      "Epoch 36/50\n",
      "198/198 [==============================] - 3s 18ms/step - loss: 0.3531 - accuracy: 0.8820 - val_loss: 0.7361 - val_accuracy: 0.8182\n",
      "Epoch 37/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.4000 - accuracy: 0.8725 - val_loss: 0.6833 - val_accuracy: 0.8246\n",
      "Epoch 38/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3780 - accuracy: 0.8809 - val_loss: 0.7235 - val_accuracy: 0.8138\n",
      "Epoch 39/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3931 - accuracy: 0.8733 - val_loss: 0.7551 - val_accuracy: 0.8227\n",
      "Epoch 40/50\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.4021 - accuracy: 0.8751 - val_loss: 0.7331 - val_accuracy: 0.8125\n",
      "Epoch 41/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3581 - accuracy: 0.8858 - val_loss: 0.7710 - val_accuracy: 0.8163\n",
      "Epoch 42/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3742 - accuracy: 0.8873 - val_loss: 0.7282 - val_accuracy: 0.8214\n",
      "Epoch 43/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3576 - accuracy: 0.8865 - val_loss: 0.7721 - val_accuracy: 0.8144\n",
      "Epoch 44/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3800 - accuracy: 0.8844 - val_loss: 0.7527 - val_accuracy: 0.8182\n",
      "Epoch 45/50\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.3364 - accuracy: 0.8936 - val_loss: 0.8053 - val_accuracy: 0.8195\n",
      "Epoch 46/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3284 - accuracy: 0.8976 - val_loss: 0.7665 - val_accuracy: 0.8208\n",
      "Epoch 47/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3558 - accuracy: 0.8934 - val_loss: 0.7580 - val_accuracy: 0.8214\n",
      "Epoch 48/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3230 - accuracy: 0.8987 - val_loss: 0.8031 - val_accuracy: 0.8113\n",
      "Epoch 49/50\n",
      "198/198 [==============================] - 3s 17ms/step - loss: 0.3437 - accuracy: 0.8919 - val_loss: 0.7193 - val_accuracy: 0.8372\n",
      "Epoch 50/50\n",
      "198/198 [==============================] - 4s 18ms/step - loss: 0.2963 - accuracy: 0.9080 - val_loss: 0.8105 - val_accuracy: 0.8163\n",
      "Fold 10: Test Loss = 2.5922, Test Accuracy = 0.4982\n",
      "\n",
      "Resultados Finais:\n",
      "Acurácia Média: 50.77%\n",
      "Desvio Padrão da Acurácia: 6.28%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "# Parâmetros\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "# Resultados por fold\n",
    "fold_accuracies = []\n",
    "fold_losses = []\n",
    "\n",
    "for test_fold_idx in range(10):  # 10 folds no UrbanSound8K\n",
    "    # Teste: O fold atual\n",
    "    X_test = X_folds[test_fold_idx]\n",
    "    y_test = y_folds[test_fold_idx]\n",
    "\n",
    "    # Treino + Validação: Os demais folds\n",
    "    X_train_val = np.concatenate([X_folds[i] for i in range(10) if i != test_fold_idx], axis=0)\n",
    "    y_train_val = np.concatenate([y_folds[i] for i in range(10) if i != test_fold_idx], axis=0)\n",
    "\n",
    "    # Normalizar os dados\n",
    "    scaler = StandardScaler()\n",
    "    X_train_val = scaler.fit_transform(X_train_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    # Divisão treino/validação\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Transformar rótulos em one-hot encoding\n",
    "    y_train = to_categorical(y_train, num_classes=num_classes)\n",
    "    y_val = to_categorical(y_val, num_classes=num_classes)\n",
    "    y_test = to_categorical(y_test, num_classes=num_classes)\n",
    "\n",
    "    # Criar o modelo\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        Dropout(0.3),\n",
    "        Dense(256, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Compilar o modelo\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Treinar o modelo\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Avaliar no conjunto de teste\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "    fold_accuracies.append(test_accuracy)\n",
    "    fold_losses.append(test_loss)\n",
    "\n",
    "    print(f\"Fold {test_fold_idx + 1}: Test Loss = {test_loss:.4f}, Test Accuracy = {test_accuracy:.4f}\")\n",
    "\n",
    "# Resultados finais\n",
    "mean_accuracy = np.mean(fold_accuracies)\n",
    "std_accuracy = np.std(fold_accuracies)\n",
    "\n",
    "print(f\"\\nResultados Finais:\")\n",
    "print(f\"Acurácia Média: {mean_accuracy * 100:.2f}%\")\n",
    "print(f\"Desvio Padrão da Acurácia: {std_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exemplo para o último fold (pode iterar por todos os folds, se necessário)\n",
    "plt.plot(history.history['accuracy'], label='Treino')\n",
    "plt.plot(history.history['val_accuracy'], label='Validação')\n",
    "plt.title('Acurácia por Épocas')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gráfico de Acurácia por Fold\n",
    "plt.bar(range(1, 11), fold_accuracies)\n",
    "plt.title('Acurácia por Fold')\n",
    "plt.xlabel('Fold')\n",
    "plt.ylabel('Acurácia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
